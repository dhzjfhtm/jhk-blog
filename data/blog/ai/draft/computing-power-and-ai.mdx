---
title: 'AI의 지능의 이론적 한계'
date: '2023-10-07'
tags: ['ai']
draft: true
summary: ''
---

# AI의 성능을 결정하는것?

현재 AI의 지능을 결정하는 것으로 알려진 것은 AI의 아키텍쳐와 그 시스템의 연산량이라고 알려져 있다. 즉 AI의 성능을 올리기 위해서 하는 것은 아키텍쳐를 더 효율적으로 바꾸거나 아니면 연산량을 늘리는, 스케일을 키운다고도 표현하는 방법을 사용하는 것이다.

하나의 사고실험을 해보자. 하나의 양성자로 이루어진 계가 지능이라고 불리는 것을 만들어 내기에 충분한가? 아마 아닐 것이다. 지능이라는 것을 발생시키기 위해서 필요한 물리적 행위를 생각해 보면 아마 연산이 가장 중요한 행위일 것이다. 단순히 생각하는 수학적 연산만이 아닌 물리적으로 연산이라고 할 수 있는 현상을 모두 포함하는 것이다.

란다우어의 정리를 생각해 보면 1비트의 정보를 지우기 위해서 필요한 최소한의 엔트로피의 증가가 존재한다.

IDEA: 지능은 연산량에 의해 구속되는 한계가 존재한다.

지능이 하나의 정보의 집합체로 생각해 보고 인풋의 정보가 지능이라는 연산을 거친후에 아웃풋이라는 정보로 변환이 되는 것을 생각해 보라. 유용한 것이 이 과정에서 만들어 졌다면 이는 정보의 측면에서는 엔트로피가 감소하는 과정이며 그 행위의 물리적 측면에서는 지능이라는 것을 매개한 연산을 통해 엔트로피가 증가하는 과정이다. 즉 지능은 엔트로피를 분리하는 성능 혹은 정보의 엔트로피를 낮추는 성능을 의미하게 된다.

Consider intelligence as a collection of information, and think about the process where the information from input goes through the operation of intelligence and is transformed into output information. If something useful is created in this process, it represents a decrease in entropy from the perspective of information, while from the physical aspect of the action, it's a process of increasing entropy through the operation mediated by intelligence. In other words, intelligence signifies the capability of segregating entropy or reducing the entropy of information.
